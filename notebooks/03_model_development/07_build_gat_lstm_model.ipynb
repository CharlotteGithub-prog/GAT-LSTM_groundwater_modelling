{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "\n",
    "# Load project Imports\n",
    "from src.utils.config_loader import load_project_config\n",
    "from src.model.model_building import build_data_loader, instantiate_model_and_associated\n",
    "from src.training.model_training import run_training_and_validation, save_train_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger config\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "   format='%(levelname)s - %(message)s',\n",
    "#    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# Set up logger for file and load config file for paths and params\n",
    "logger = logging.getLogger(__name__)\n",
    "config = load_project_config(config_path=\"config/project_config.yaml\")\n",
    "notebook = True\n",
    "\n",
    "# Set up seeding to define global states\n",
    "random_seed = config[\"global\"][\"pipeline_settings\"][\"random_seed\"]\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define notebook demo catchment\n",
    "catchments_to_process = config[\"global\"][\"pipeline_settings\"][\"catchments_to_process\"]\n",
    "catchment = catchments_to_process[0]\n",
    "run_defra_API_calls = config[\"global\"][\"pipeline_settings\"][\"run_defra_api\"]\n",
    "\n",
    "logger.info(f\"Show Notebook Outputs: {notebook}\")\n",
    "logger.info(f\"Notebook Demo Catchment: {catchment.capitalize()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timesteps_list = torch.load(config[catchment][\"paths\"][\"pyg_object_path\"])\n",
    "all_timesteps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks\n",
    "example_data_obj = all_timesteps_list[0]\n",
    "logger.info(example_data_obj.x.shape)\n",
    "logger.info(example_data_obj.train_mask.sum(), example_data_obj.val_mask.sum(), example_data_obj.test_mask.sum())\n",
    "logger.info(example_data_obj.timestep)\n",
    "\n",
    "train_counts = sum(d.train_mask.sum().item() for d in all_timesteps_list)\n",
    "val_counts = sum(d.val_mask.sum().item() for d in all_timesteps_list)\n",
    "test_counts = sum(d.test_mask.sum().item() for d in all_timesteps_list)\n",
    "\n",
    "logger.info(f\"\\nTotal (across all timesteps) — Train: {train_counts}, Val: {val_counts}, Test: {test_counts}\\n\")\n",
    "\n",
    "x_tensor = example_data_obj.x\n",
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7a. Build Data Loaders by Timestep ---\n",
    "\n",
    "full_dataset_loader = build_data_loader(\n",
    "    all_timesteps_list=all_timesteps_list,\n",
    "    batch_size = config[\"global\"][\"model\"][\"data_loader_batch_size\"],\n",
    "    shuffle = config[\"global\"][\"model\"][\"data_loader_shuffle\"],\n",
    "    catchment=catchment\n",
    ")\n",
    "\n",
    "logger.info(f\"Pipeline Step 'Create PyG DataLoaders' complete for {catchment} catchment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7b. Define Graph Neural Network Architecture ---\n",
    "\n",
    "model, device, optimizer, criterion = instantiate_model_and_associated(\n",
    "    all_timesteps_list=all_timesteps_list,\n",
    "    config=config,\n",
    "    catchment=catchment\n",
    ")\n",
    "\n",
    "logger.info(f\"Pipeline Step 'Instantiate GAT-LSTM Model' complete for {catchment} catchment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8a. Implement Training Loop ---\n",
    "\n",
    "train_losses, val_losses = run_training_and_validation(\n",
    "    num_epochs=config[catchment][\"training\"][\"num_epochs\"],\n",
    "    early_stopping_patience=config[catchment][\"training\"][\"early_stopping_patience\"],\n",
    "    lr_scheduler_factor=config[catchment][\"training\"][\"lr_scheduler_factor\"],\n",
    "    lr_scheduler_patience=config[catchment][\"training\"][\"lr_scheduler_patience\"],\n",
    "    min_lr=config[catchment][\"training\"][\"min_lr\"],\n",
    "    gradient_clip_max_norm=config[catchment][\"training\"][\"gradient_clip_max_norm\"],\n",
    "    model_save_dir=config[catchment][\"paths\"][\"model_dir\"],\n",
    "    loss_delta=config[catchment][\"training\"][\"loss_delta\"],\n",
    "    verbose=config[catchment][\"training\"][\"verbose\"],\n",
    "    catchment=catchment,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    all_timesteps_list=all_timesteps_list,\n",
    "    scalers_dir=config[catchment][\"paths\"][\"scalers_dir\"],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "logger.info(f\"Pipeline Step 'Train and Validate Model' complete for {catchment} catchment.\")\n",
    "\n",
    "save_train_val_losses(\n",
    "    output_analysis_dir=config[catchment][\"paths\"][\"model_dir\"],\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses\n",
    ")\n",
    "\n",
    "logger.info(f\"Pipeline Step 'Save Training and Validation Losses' complete for {catchment} catchment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Next Steps: Final Model Evaluation on Test Set (using all_timesteps_list and data.test_mask) ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
