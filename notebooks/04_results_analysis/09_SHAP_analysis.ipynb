{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library imports\n",
    "import os\n",
    "import sys\n",
    "import shap\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load project Imports\n",
    "from src.utils.config_loader import load_project_config, deep_format, expanduser_tree\n",
    "from src.model.GAT_LSTM_class import GAT_LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger config\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "   format='%(levelname)s - %(message)s',\n",
    "#    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# Set up logger for file and load config file for paths and params\n",
    "logger = logging.getLogger(__name__)\n",
    "config = load_project_config(config_path=\"config/project_config.yaml\")\n",
    "notebook = True\n",
    "\n",
    "# Set up root directory paths in config\n",
    "raw_data_root = config[\"global\"][\"paths\"][\"raw_data_root\"]\n",
    "results_root = config[\"global\"][\"paths\"][\"results_root\"]\n",
    " \n",
    "# Reformat config roots\n",
    "config = deep_format(\n",
    "    config,\n",
    "    raw_data_root=raw_data_root,\n",
    "    results_root=results_root\n",
    ")\n",
    "config = expanduser_tree(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seeding to define global states\n",
    "random_seed = config[\"global\"][\"pipeline_settings\"][\"random_seed\"]\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define notebook demo catchment\n",
    "catchments_to_process = config[\"global\"][\"pipeline_settings\"][\"catchments_to_process\"]\n",
    "catchment = catchments_to_process[0]\n",
    "run_defra_API_calls = config[\"global\"][\"pipeline_settings\"][\"run_defra_api\"]\n",
    "\n",
    "logger.info(f\"Show Notebook Outputs: {notebook}\")\n",
    "logger.info(f\"Notebook Demo Catchment: {catchment.capitalize()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in timesteps PyG Object\n",
    "all_timesteps_list = torch.load(config[catchment][\"paths\"][\"pyg_object_path\"])\n",
    "all_timesteps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load GAT-LSTM Model and Data Loaders ---\n",
    "\n",
    "# Define model checkpoint path\n",
    "checkpoint_path = \"data/04_model/eden/model/pt_model/model_20250812-092352_GATTrue_LSTMFalse_GATH12_GATD0-4_GATHC64_GATOC64_GATNL2_LSTHC32_LSTNL1_OUTD1_LR0-001_WD0-001_SM0-1_E200_ESP30_LRSF0-5_LRSP8_MINLR1e-06_LD0-0001_GCMN1-0.pt\"\n",
    "\n",
    "# Load model hyperparameters from config\n",
    "model_config = config[catchment][\"model\"][\"architecture\"]\n",
    "training_config = config[catchment][\"training\"]\n",
    "\n",
    "temporal_features = model_config[\"temporal_features\"]\n",
    "temporal_features_dim = len(temporal_features)\n",
    "in_channels = all_timesteps_list[0].x.shape[1]\n",
    "\n",
    "# Instantiate the model class\n",
    "model = GAT_LSTM_Model(\n",
    "    in_channels=in_channels,\n",
    "    temporal_features_dim=temporal_features_dim,\n",
    "    static_features_dim=in_channels - temporal_features_dim,\n",
    "    hidden_channels_gat=model_config[\"hidden_channels_gat\"],\n",
    "    out_channels_gat=model_config[\"out_channels_gat\"],\n",
    "    heads_gat=model_config[\"heads_gat\"],\n",
    "    dropout_gat=model_config[\"dropout_gat\"],\n",
    "    hidden_channels_lstm=model_config[\"hidden_channels_lstm\"],\n",
    "    num_layers_lstm=model_config[\"num_layers_lstm\"],\n",
    "    num_layers_gat=model_config[\"num_layers_gat\"],\n",
    "    num_nodes=len(all_timesteps_list[0].x),\n",
    "    output_dim=model_config[\"output_dim\"],\n",
    "    run_GAT=model_config[\"run_GAT\"],\n",
    "    run_LSTM=model_config[\"run_LSTM\"],\n",
    "    random_seed=random_seed,\n",
    "    catchment=catchment,\n",
    "    run_node_conditioner=model_config[\"run_node_conditioner\"],\n",
    "    fusion_mode=model_config[\"fusion_mode\"]\n",
    ")\n",
    "\n",
    "# Load trained model (checkpoint) state\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "logger.info(f\"Successfully loaded model from {checkpoint_path}\")\n",
    "model.eval()\n",
    "\n",
    "# Run data loader\n",
    "data_loader = DataLoader(all_timesteps_list, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define custom SHAP prediction wrapper ---\n",
    "\n",
    "# Create PyG model from numpy array\n",
    "def predict_func_shap(data_as_numpy):\n",
    "    \"\"\"\n",
    "    This takes a numpy array, reconstructs the PyG object needed for the forward pass of the model and\n",
    "    returns a np array again as needed for SHAP analysis.\n",
    "    \n",
    "    NOTE: It assumes edge_index and edge_attr are the same for all timesteps (currently current but\n",
    "    will need adjusting in future if this changes).\n",
    "    \"\"\"\n",
    "    # Initialise predictions list to build array\n",
    "    predictions = []\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # If using LSTM state then store it (fill tnesor initially with zeros)\n",
    "    if model.run_LSTM:\n",
    "        lstm_state_store = {\n",
    "            'h': torch.zeros(model.num_layers_lstm, model.num_nodes, model.hidden_channels_lstm),\n",
    "            'c': torch.zeros(model.num_layers_lstm, model.num_nodes, model.hidden_channels_lstm)\n",
    "        }\n",
    "    \n",
    "    # Ensure no gradient and iterate over each sample provided by SHAP\n",
    "    with torch.no_grad():\n",
    "        for sample in data_as_numpy:\n",
    "            \n",
    "            # Reconstruct the PyG Data object from the NumPy feature array\n",
    "            data_obj = Data(x=torch.tensor(sample.reshape(model.num_nodes, -1), dtype=torch.float32),\n",
    "                            edge_index=all_timesteps_list[0].edge_index,\n",
    "                            edge_attr=all_timesteps_list[0].edge_attr,\n",
    "                            node_id=all_timesteps_list[0].node_id)\n",
    "            \n",
    "            # Define vars required for fwd pass\n",
    "            x_full = data_obj.x\n",
    "            node_ids_in_current_timestep = data_obj.node_id\n",
    "            \n",
    "            # Run forward pass using reconstructed data object\n",
    "            predictions_all_nodes, _, _ = (\n",
    "                x_full, data_obj.edge_index, data_obj.edge_attr, node_ids_in_current_timestep, lstm_state_store\n",
    "            )\n",
    "            \n",
    "            # Flatten the output (SHAP works with one pred per input row). This is an oversimplification but works for summary\n",
    "            predictions.append(predictions_all_nodes.cpu().numpy().flatten())\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare data for SHAP Explainer ---\n",
    "\n",
    "# KernelExplainer expects a 2D NumPy array (samples x features) - so flatten node features by timestep.\n",
    "\n",
    "# Use small subset of timesteps for background data\n",
    "background_data_list = [data.x.numpy().flatten() for data in all_timesteps_list[:10]]\n",
    "background_data_array = np.vstack(background_data_list)\n",
    "\n",
    "# Use small subset again for the samples to explain\n",
    "samples_to_explain_list = [data.x.numpy().flatten() for data in all_timesteps_list[10:20]]\n",
    "samples_to_explain_array = np.vstack(samples_to_explain_list)\n",
    "\n",
    "\n",
    "# Set up the SHAP Explainer and get SHAP values using PyG reconstruction func (computationally intensive)\n",
    "explainer = shap.KernelExplainer(predict_func_shap, background_data_array)\n",
    "logger.info(\"Calculating SHAP values... This may take a while.\")\n",
    "shap_values = explainer.shap_values(samples_to_explain_array) # SHAP vals have same shape as flattened input feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualise the SHAP results ---\n",
    "\n",
    "# Build flattened list of feature names for each node\n",
    "feature_names = all_timesteps_list[0].features\n",
    "node_ids = all_timesteps_list[0].node_id.tolist()\n",
    "\n",
    "# Get feature names for summary\n",
    "flat_feature_names = [f\"Node {node_id}: {feat_name}\" for node_id in node_ids for feat_name in feature_names]\n",
    "\n",
    "# Generate summary plot o fhte impact of each flattened feature in the final model\n",
    "logger.info(\"\\nGenerating SHAP summary plot...\")\n",
    "shap.summary_plot(shap_values, samples_to_explain_array, feature_names=flat_feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise a single prediction (e.g. [0] for the first sample)\n",
    "logger.info(\"\\nGenerating SHAP force plot for a single instance...\")\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], samples_to_explain_array[0], feature_names=flat_feature_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
